---
layout:     post
title:      "机器人学中的状态估计-04"
subtitle:   "NLNG系统下滤波器 - 1"
date:       2020-12-04
author:     "Yvan"
header-img: "img/in-post/rse-4.jpg"
header-mask: 0.3
no-catalog: false
mathjax: true
tags:
    - SER
typora-root-url: ..
typora-copy-images-to: ..\img\in-post\ser\04
---

# Estimation Machinery

# K4 Nonlinear Non-Gaussian Estimation-1

## 上回总结

>  定义问题 
>
>  -> 批量处理方法的 MAP & 贝叶斯 得到同一个方程 (MAP是模，贝叶斯是均值)
>
>  -> Cholesky分解解方程HWH=LL 前向后向 得到一些关于L的迭代方程组
>
>  -> 继续变形 消去L 变成RTS Smoother（4+1信息形式/5+1经典形式）
>
>  如果不走批量方法，直接走迭代方法
>
>  -> 递归处理方法的 MAP & 贝叶斯
>
>  -> 得到4/5个方程 叫做 卡尔曼滤波器（和RTS中前向部分的一样）



## 这回内容

0. 问题setup
1. **贝叶斯滤波器**： 基于贝叶斯公式，只是理想的数学模型。
2. **扩展卡尔曼**：线性变化以后代入贝叶斯滤波器。
3. **迭代扩展卡尔曼**：

---

### Setup 1

$\frac{b}{x} = \frac{b-v+u}{f+x}$

<img src="/img/in-post/ser/04/image-20201205113520559.png" alt="image-20201205113520559" style="zoom: 33%;" />

#### Bayesian

<img src="/img/in-post/ser/04/image-20201205131301834.png" alt="image-20201205131301834" style="zoom: 67%;" />

**Bayesian Framework**

<img src="/img/in-post/ser/04/image-20201205131938741.png" alt="image-20201205131938741" style="zoom:50%;" />

We start with a prior. The 'true' state is then drawn from
the prior, and the measurement is generated by observing the true
state through the camera model and adding noise. The estimator then
reconstructs the posterior from the measurement and prior, without knowing x_true.



#### MAP

<img src="/img/in-post/ser/04/image-20201205131324105.png" alt="image-20201205131324105" style="zoom: 67%;" />

<img src="/img/in-post/ser/04/image-20201205131343520.png" alt="image-20201205131343520" style="zoom: 67%;" />

<img src="/img/in-post/ser/04/image-20201205131414920.png" alt="image-20201205131414920" style="zoom:67%;" />

for the example of stereo camera:

<img src="/img/in-post/ser/04/image-20201205131601336.png" alt="image-20201205131601336" style="zoom: 56%;" />

<img src="/img/in-post/ser/04/image-20201205131610161.png" alt="image-20201205131610161" style="zoom:56%;" />

so:

<img src="/img/in-post/ser/04/image-20201205132320649.png" alt="image-20201205132320649" style="zoom: 67%;" />

<img src="/img/in-post/ser/04/image-20201205132332336.png" alt="image-20201205132332336" style="zoom:67%;" />

---

### Setup 2

<img src="/img/in-post/ser/04/image-20201205154523619.png" alt="image-20201205154523619" style="zoom:50%;" />

<img src="/img/in-post/ser/04/image-20201205154538245.png" alt="image-20201205154538245" style="zoom:50%;" />

**Markov Property**

the conditional PDF of future states of the process, given the present state, depend only upon the present state, but not on any other past states, i.e., they are conditionally independent of these older states. Such a process is called Markovian or a Markov process.

<img src="/img/in-post/ser/04/image-20201205154851751.png" alt="image-20201205154851751" style="zoom:50%;" />

---

### Bayes Filter

目的：计算  belief function

<img src="/img/in-post/ser/04/image-202012140014087021.png" alt="image-202012140014087021" style="zoom: 50%;" />

**第一步**：用贝叶斯公式展开

<img src="/img/in-post/ser/04/image-20201214001408702.png" alt="image-20201214001408702" style="zoom: 50%;" />

第一步原理：贝叶斯公式：

<center>
$p(x \mid y,z) = $ <font size=5> $\frac{p(y \mid x,z) \cdot p(x \mid z)}{p(y\mid z)} $</font><br/>
here,   $x = x_k \qquad \qquad  y = y_k \qquad \qquad z = x_0, v_1:v_k,y_0:y_{k-1}$<br/>
其中p(y|z)是常数，因为当前的测量之和当前状态有关和{输入,之前的测量,之前的状态}无关。
 </center>

**第二步**：计算p(x\|z)

<img src="/img/in-post/ser/04/image-20201214002541751.png" alt="image-20201214002541751" style="zoom:50%;" />

第二布原理：全概率公式 + 条件概率公式

<img src="/img/in-post/ser/04/image-20201214003235008.png" alt="image-20201214003235008" style="zoom: 67%;" />

<center>
$p(x，y \mid z) = p(x \mid y,z) \cdot p(y \mid z) $<br/>
 </center>

**第三步**：简化积分中的两项：**hidden state / inverse of marginalization**

<img src="/img/in-post/ser/04/image-20201214003701959.png" alt="image-20201214003701959" style="zoom:50%;" />

第三步原理：马尔可夫性质

当一个随机过程在给定现在状态及所有过去状态情况下，其未来状态的条件概率分布仅依赖于当前状态。

**第四步**：联立

<img src="/img/in-post/ser/04/image-20201214004019541.png" alt="image-20201214004019541" style="zoom:50%;" />

**可见**：

$x$实现递归推导。

这个状态 = 用g测量得**矫正** * 用运动模式f的**预测** * 上一个状态

是一个**predictor-corrector**的形式，和卡尔曼滤波器一样。矫正和预测只和**当前**和**上一个状态**有关。

<img src="/img/in-post/ser/04/image-20201214004543113.png" alt="image-20201214004543113" style="zoom:50%;" />

**但是：**

只是一个数学模型，除线性高斯系统中，不可能实践。

1. **infinite amount of memory**: 需要用于储存v1-vk, y0-yk的无限储存空间。
2. **infinite computing resources**: 计算积分的代价很大。

---

### Extended Kalman Filter

先上结论以及与LG系统下的KF的比较：

<img src="/img/in-post/ser/04/image-20201214010531893.png" alt="image-20201214010531893" style="zoom:50%;" />

**前提/假设：**

1. prior是高斯分布。

2. 两个噪音w,n是零均值高斯分布，且无关。

3. 运动和观测方程f,g被线性化。（线性化方法在[SER-1-2.2.8](https://yvvvan.github.io/2020/10/26/SER/#228-nonlinear-change)中提到）

4. 运动和观测方程的线性化取在如下两个点上：

   <img src="/img/in-post/ser/04/image-20201214012227971.png" alt="image-20201214012227971" style="zoom:50%;" />

---

待续 14.12.2020